{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dimna21/ML_Assignment4/blob/main/FER2013.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ZLXW_6vaKhx",
        "outputId": "30c673f2-cbf8-4b8f-9f9c-d41a304386f4"
      },
      "id": "3ZLXW_6vaKhx",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (0.19.11)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb) (8.2.1)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.1.44)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb) (4.3.8)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.29.4)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.11.4)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from wandb) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.32.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.29.1)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb) (1.3.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb) (75.2.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.11/dist-packages (from wandb) (4.13.2)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2025.4.26)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "wandb.login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "id": "nqno6c80fPyn",
        "outputId": "28e768f7-b260-466c-fda0-fa511de5d674"
      },
      "id": "nqno6c80fPyn",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdimna21\u001b[0m (\u001b[33mdimna21-free-university-of-tbilisi-\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "txE_ZZpJWh4M",
        "outputId": "d5270572-9a8e-41fc-8c29-6a3d04563b12"
      },
      "id": "txE_ZZpJWh4M",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# Load the CSV\n",
        "csv_path = \"/content/drive/MyDrive/FER_data/fer2013/fer2013.csv\"\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "# Split by Usage\n",
        "df_train = df[df['Usage']==\"Training\"].copy()\n",
        "df_val   = df[df['Usage']==\"PublicTest\"].copy()\n",
        "df_test  = df[df['Usage']==\"PrivateTest\"].copy()"
      ],
      "metadata": {
        "id": "_kISQ9MWPnq9"
      },
      "id": "_kISQ9MWPnq9",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Balance function: upsampling & random ±10 intensity shifts\n",
        "def balance_dataset(df, target_count, img_shape=(48,48)):\n",
        "    def augment(pix_str):\n",
        "        arr = np.fromstring(pix_str, sep=' ', dtype=int).reshape(img_shape)\n",
        "        shift = np.random.randint(-10, 11)\n",
        "        arr = np.clip(arr + shift, 0, 255).astype(int)\n",
        "        return ' '.join(map(str, arr.ravel()))\n",
        "    parts = [df]\n",
        "    for emo, grp in df.groupby('emotion'):\n",
        "        n = len(grp)\n",
        "        if n < target_count:\n",
        "            extra = grp.sample(n=target_count-n, replace=True).copy()\n",
        "            extra['pixels'] = extra['pixels'].map(augment)\n",
        "            parts.append(extra)\n",
        "    return pd.concat(parts, ignore_index=True)\n"
      ],
      "metadata": {
        "id": "KvawHlnpW48u"
      },
      "id": "KvawHlnpW48u",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset class\n",
        "class FERDataset(Dataset):\n",
        "    def __init__(self, dataframe):\n",
        "        self.pixels = dataframe['pixels'].values\n",
        "        self.labels = dataframe['emotion'].values.astype(int)\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "    def __getitem__(self, idx):\n",
        "        arr = np.fromstring(self.pixels[idx], sep=' ', dtype=np.uint8).reshape(48,48)\n",
        "        arr = arr.astype(np.float32) / 255.0\n",
        "        tensor = torch.from_numpy(arr).unsqueeze(0)  # shape [1,48,48]\n",
        "        return tensor, self.labels[idx]\n"
      ],
      "metadata": {
        "id": "h1q4nlYyXBxE"
      },
      "id": "h1q4nlYyXBxE",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v9JYy7z7YM0F",
        "outputId": "77824021-66ad-42c2-983a-aefacde9d6b2"
      },
      "id": "v9JYy7z7YM0F",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DataLoaders\n",
        "max_count = df_train['emotion'].value_counts().max()\n",
        "balanced_train = balance_dataset(df_train, target_count=max_count)\n",
        "\n",
        "train_ds = FERDataset(balanced_train)\n",
        "val_ds = FERDataset(df_val)\n",
        "test_ds = FERDataset(df_test)\n",
        "\n",
        "batch_size = 128\n",
        "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True,  num_workers=2)\n",
        "val_dl = DataLoader(val_ds,   batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "test_dl = DataLoader(test_ds,  batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "# Class names\n",
        "class_names = [\"Angry\", \"Disgust\", \"Fear\", \"Happy\", \"Sad\", \"Surprise\", \"Neutral\"]"
      ],
      "metadata": {
        "id": "cqg0BQ4hY49l"
      },
      "id": "cqg0BQ4hY49l",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from tqdm import tqdm\n",
        "import wandb\n",
        "from sklearn.metrics import confusion_matrix, f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def train_model(model, train_loader, val_loader,\n",
        "                criterion, optimizer, device,\n",
        "                epochs=5, class_names=None):\n",
        "\n",
        "    wandb.init(\n",
        "        project=\"ML_Assignment4\",\n",
        "        config={\n",
        "            \"epochs\": epochs,\n",
        "            \"batch_size\": train_loader.batch_size,\n",
        "            \"optimizer\": optimizer.__class__.__name__,\n",
        "            \"lr\": optimizer.param_groups[0][\"lr\"],\n",
        "            \"criterion\": criterion.__class__.__name__,\n",
        "        },\n",
        "    )\n",
        "    cfg = wandb.config\n",
        "    wandb.watch(model, log=\"all\", log_freq=100)\n",
        "    model.to(device)\n",
        "\n",
        "    train_loss_plot, val_loss_plot = [], []\n",
        "    train_acc_plot,  val_acc_plot  = [], []\n",
        "\n",
        "    for epoch in range(1, cfg.epochs + 1):\n",
        "        # — TRAIN —\n",
        "        model.train()\n",
        "        running_loss = running_correct = running_total = 0\n",
        "        for X, y in tqdm(train_loader, desc=f\"Epoch {epoch} [Train]\"):\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            out = model(X)\n",
        "            loss = criterion(out, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss    += loss.item() * X.size(0)\n",
        "            preds            = out.argmax(dim=1)\n",
        "            running_correct += preds.eq(y).sum().item()\n",
        "            running_total   += y.size(0)\n",
        "\n",
        "        train_loss = running_loss / running_total\n",
        "        train_acc  = running_correct / running_total\n",
        "\n",
        "        # — VALIDATE —\n",
        "        model.eval()\n",
        "        val_running_loss = val_running_correct = val_running_total = 0\n",
        "        all_preds, all_targets = [], []\n",
        "        with torch.no_grad():\n",
        "            for X, y in tqdm(val_loader, desc=f\"Epoch {epoch} [Val]\"):\n",
        "                X, y = X.to(device), y.to(device)\n",
        "                out = model(X)\n",
        "                loss = criterion(out, y)\n",
        "\n",
        "                val_running_loss    += loss.item() * X.size(0)\n",
        "                preds                = out.argmax(dim=1)\n",
        "                val_running_correct += preds.eq(y).sum().item()\n",
        "                val_running_total   += y.size(0)\n",
        "\n",
        "                all_preds.extend(preds.cpu().numpy())\n",
        "                all_targets.extend(y.cpu().numpy())\n",
        "\n",
        "        val_loss = val_running_loss / val_running_total\n",
        "        val_acc  = val_running_correct / val_running_total\n",
        "\n",
        "        # — SCALARS & F1 —\n",
        "        cm = confusion_matrix(all_targets, all_preds)\n",
        "        f1_per_class = f1_score(all_targets, all_preds, average=None)\n",
        "\n",
        "        log_data = {\n",
        "            \"train_loss\": train_loss,\n",
        "            \"train_acc\":  train_acc,\n",
        "            \"val_loss\":   val_loss,\n",
        "            \"val_acc\":    val_acc,\n",
        "        }\n",
        "        for i, name in enumerate(class_names):\n",
        "            log_data[f\"f1_{name}\"] = f1_per_class[i]\n",
        "\n",
        "        wandb.log(log_data, step=epoch)\n",
        "\n",
        "        # — 7×7 Confusion Matrix Plot & Log —\n",
        "        fig_cm, ax = plt.subplots(figsize=(6,6))\n",
        "        im = ax.imshow(cm, interpolation='nearest', cmap='Blues')\n",
        "        fig_cm.colorbar(im, ax=ax)\n",
        "\n",
        "        ax.set_xticks(np.arange(len(class_names)))\n",
        "        ax.set_yticks(np.arange(len(class_names)))\n",
        "        ax.set_xticklabels(class_names, rotation=45, ha='right')\n",
        "        ax.set_yticklabels(class_names)\n",
        "\n",
        "        for i in range(len(class_names)):\n",
        "            for j in range(len(class_names)):\n",
        "                ax.text(j, i, cm[i, j],\n",
        "                        ha='center', va='center')\n",
        "\n",
        "        ax.set_xlabel('Predicted')\n",
        "        ax.set_ylabel('Actual')\n",
        "        ax.set_title(f'Epoch {epoch} Confusion Matrix')\n",
        "\n",
        "        wandb.log({\"confusion_matrix\": wandb.Image(fig_cm)}, step=epoch)\n",
        "        plt.close(fig_cm)\n",
        "\n",
        "        # — PRINT & STORE FOR CURVES —\n",
        "        print(\n",
        "            f\"Epoch {epoch}/{cfg.epochs} — \"\n",
        "            f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}  |  \"\n",
        "            f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\"\n",
        "        )\n",
        "        print(\"-\" * 60)\n",
        "\n",
        "        train_loss_plot.append(train_loss)\n",
        "        val_loss_plot.append(val_loss)\n",
        "        train_acc_plot.append(train_acc)\n",
        "        val_acc_plot.append(val_acc)\n",
        "\n",
        "    # — PLOT & LOG LOSS/ACC CURVES TO W&B —\n",
        "    epochs_range = list(range(1, cfg.epochs + 1))\n",
        "\n",
        "    # Loss curve\n",
        "    fig1, ax1 = plt.subplots()\n",
        "    ax1.plot(epochs_range, train_loss_plot, label=\"Train Loss\")\n",
        "    ax1.plot(epochs_range, val_loss_plot,   label=\"Val Loss\")\n",
        "    ax1.set(title=\"Loss vs Epoch\", xlabel=\"Epoch\", ylabel=\"Loss\")\n",
        "    ax1.legend()\n",
        "    wandb.log({\"loss_curve\": wandb.Image(fig1)})\n",
        "    plt.close(fig1)\n",
        "\n",
        "    # Accuracy curve\n",
        "    fig2, ax2 = plt.subplots()\n",
        "    ax2.plot(epochs_range, train_acc_plot, label=\"Train Acc\")\n",
        "    ax2.plot(epochs_range, val_acc_plot,   label=\"Val Acc\")\n",
        "    ax2.set(title=\"Accuracy vs Epoch\", xlabel=\"Epoch\", ylabel=\"Accuracy\")\n",
        "    ax2.legend()\n",
        "    wandb.log({\"acc_curve\": wandb.Image(fig2)})\n",
        "    plt.close(fig2)\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "yUaGVGmwYp9q"
      },
      "id": "yUaGVGmwYp9q",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BaselineModel(nn.Module):\n",
        "    def __init__(self):\n",
        "      super().__init__()\n",
        "\n",
        "      self.conv1 = nn.Conv2d(1, 32, kernel_size = 3, padding = 1)\n",
        "      self.conv2 = nn.Conv2d(32, 64, kernel_size = 3, padding = 1)\n",
        "      self.conv3 = nn.Conv2d(64, 128, kernel_size = 3, padding = 1)\n",
        "      self.pooling = nn.MaxPool2d(2,2)\n",
        "      self.relu = nn.ReLU()\n",
        "\n",
        "      self.flatten = nn.Flatten()\n",
        "      self.linear = nn.Linear((128 * 6 * 6), 128)\n",
        "      self.output = nn.Linear(128, 7)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "      x = self.conv1(x)\n",
        "      x = self.pooling(x)\n",
        "      x = self.relu(x)\n",
        "      x = self.conv2(x)\n",
        "      x = self.pooling(x)\n",
        "      x = self.relu(x)\n",
        "      x = self.conv3(x)\n",
        "      x = self.pooling(x)\n",
        "      x = self.relu(x)\n",
        "      x = self.flatten(x)\n",
        "      x = self.linear(x)\n",
        "      x = self.output(x)\n",
        "\n",
        "      return x"
      ],
      "metadata": {
        "id": "YTbWfJUPxuff"
      },
      "id": "YTbWfJUPxuff",
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_model = BaselineModel().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(baseline_model.parameters(), lr=1e-3)\n",
        "trained = train_model(\n",
        "    baseline_model,\n",
        "    train_dl,\n",
        "    val_dl,\n",
        "    criterion,\n",
        "    optimizer,\n",
        "    device,\n",
        "    epochs=10,\n",
        "    class_names=class_names\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "O6Vv4Tlc3cy0",
        "outputId": "73139be1-a0ac-4019-d255-709397e0d7d3"
      },
      "id": "O6Vv4Tlc3cy0",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing previous runs because reinit is set to 'default'."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>f1_Angry</td><td>▁</td></tr><tr><td>f1_Disgust</td><td>▁</td></tr><tr><td>f1_Fear</td><td>▁</td></tr><tr><td>f1_Happy</td><td>▁</td></tr><tr><td>f1_Neutral</td><td>▁</td></tr><tr><td>f1_Sad</td><td>▁</td></tr><tr><td>f1_Surprise</td><td>▁</td></tr><tr><td>train_acc</td><td>▁</td></tr><tr><td>train_loss</td><td>▁</td></tr><tr><td>val_acc</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>f1_Angry</td><td>0.29811</td></tr><tr><td>f1_Disgust</td><td>0.18845</td></tr><tr><td>f1_Fear</td><td>0.26126</td></tr><tr><td>f1_Happy</td><td>0.60232</td></tr><tr><td>f1_Neutral</td><td>0.39846</td></tr><tr><td>f1_Sad</td><td>0.15109</td></tr><tr><td>f1_Surprise</td><td>0.57737</td></tr><tr><td>train_acc</td><td>0.32347</td></tr><tr><td>train_loss</td><td>1.71568</td></tr><tr><td>val_acc</td><td>0.39621</td></tr><tr><td>val_loss</td><td>1.56463</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">crisp-silence-4</strong> at: <a href='https://wandb.ai/dimna21-free-university-of-tbilisi-/ML_Assignment4/runs/57xrnb8j' target=\"_blank\">https://wandb.ai/dimna21-free-university-of-tbilisi-/ML_Assignment4/runs/57xrnb8j</a><br> View project at: <a href='https://wandb.ai/dimna21-free-university-of-tbilisi-/ML_Assignment4' target=\"_blank\">https://wandb.ai/dimna21-free-university-of-tbilisi-/ML_Assignment4</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250529_164415-57xrnb8j/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.11"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250529_164743-7amufnzs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/dimna21-free-university-of-tbilisi-/ML_Assignment4/runs/7amufnzs' target=\"_blank\">frosty-serenity-5</a></strong> to <a href='https://wandb.ai/dimna21-free-university-of-tbilisi-/ML_Assignment4' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/dimna21-free-university-of-tbilisi-/ML_Assignment4' target=\"_blank\">https://wandb.ai/dimna21-free-university-of-tbilisi-/ML_Assignment4</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/dimna21-free-university-of-tbilisi-/ML_Assignment4/runs/7amufnzs' target=\"_blank\">https://wandb.ai/dimna21-free-university-of-tbilisi-/ML_Assignment4/runs/7amufnzs</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1 [Train]: 100%|██████████| 395/395 [00:06<00:00, 62.24it/s]\n",
            "Epoch 1 [Val]: 100%|██████████| 29/29 [00:00<00:00, 61.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10 — Train Loss: 1.6891, Train Acc: 0.3348  |  Val Loss: 1.5523, Val Acc: 0.4129\n",
            "------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2 [Train]: 100%|██████████| 395/395 [00:07<00:00, 49.69it/s]\n",
            "Epoch 2 [Val]: 100%|██████████| 29/29 [00:00<00:00, 60.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/10 — Train Loss: 1.3016, Train Acc: 0.5122  |  Val Loss: 1.4285, Val Acc: 0.4675\n",
            "------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3 [Train]: 100%|██████████| 395/395 [00:06<00:00, 63.77it/s]\n",
            "Epoch 3 [Val]: 100%|██████████| 29/29 [00:00<00:00, 63.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/10 — Train Loss: 1.0911, Train Acc: 0.5885  |  Val Loss: 1.3528, Val Acc: 0.5029\n",
            "------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4 [Train]: 100%|██████████| 395/395 [00:07<00:00, 49.66it/s]\n",
            "Epoch 4 [Val]: 100%|██████████| 29/29 [00:00<00:00, 61.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/10 — Train Loss: 0.9745, Train Acc: 0.6346  |  Val Loss: 1.4600, Val Acc: 0.4723\n",
            "------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5 [Train]: 100%|██████████| 395/395 [00:06<00:00, 64.40it/s]\n",
            "Epoch 5 [Val]: 100%|██████████| 29/29 [00:00<00:00, 57.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/10 — Train Loss: 0.8938, Train Acc: 0.6679  |  Val Loss: 1.4338, Val Acc: 0.5049\n",
            "------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6 [Train]: 100%|██████████| 395/395 [00:08<00:00, 49.32it/s]\n",
            "Epoch 6 [Val]: 100%|██████████| 29/29 [00:00<00:00, 62.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/10 — Train Loss: 0.8252, Train Acc: 0.6977  |  Val Loss: 1.4726, Val Acc: 0.5065\n",
            "------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7 [Train]: 100%|██████████| 395/395 [00:06<00:00, 63.28it/s]\n",
            "Epoch 7 [Val]: 100%|██████████| 29/29 [00:00<00:00, 59.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/10 — Train Loss: 0.7707, Train Acc: 0.7183  |  Val Loss: 1.5149, Val Acc: 0.5054\n",
            "------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8 [Train]: 100%|██████████| 395/395 [00:07<00:00, 49.55it/s]\n",
            "Epoch 8 [Val]: 100%|██████████| 29/29 [00:00<00:00, 59.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/10 — Train Loss: 0.7238, Train Acc: 0.7376  |  Val Loss: 1.5778, Val Acc: 0.5146\n",
            "------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9 [Train]: 100%|██████████| 395/395 [00:06<00:00, 64.15it/s]\n",
            "Epoch 9 [Val]: 100%|██████████| 29/29 [00:00<00:00, 33.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/10 — Train Loss: 0.6771, Train Acc: 0.7573  |  Val Loss: 1.6033, Val Acc: 0.5258\n",
            "------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10 [Train]: 100%|██████████| 395/395 [00:07<00:00, 53.14it/s]\n",
            "Epoch 10 [Val]: 100%|██████████| 29/29 [00:00<00:00, 60.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/10 — Train Loss: 0.6394, Train Acc: 0.7711  |  Val Loss: 1.6563, Val Acc: 0.5135\n",
            "------------------------------------------------------------\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}